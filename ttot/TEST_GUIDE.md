# ğŸ§ª LLM ì„œë²„ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½

**ì„œë²„ ìƒíƒœ:** ì •ìƒ ì‘ë™ âœ…
- ì„œë²„ ì‹œì‘: ì„±ê³µ
- API ì—”ë“œí¬ì¸íŠ¸: ì •ìƒ
- í—¬ìŠ¤ì²´í¬: ì •ìƒ

**ì œí•œ ì‚¬í•­:**
- ë„¤íŠ¸ì›Œí¬ í™˜ê²½ìœ¼ë¡œ ì¸í•´ OpenAI API í˜¸ì¶œì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ë¡œì»¬ í…ŒìŠ¤íŠ¸ëŠ” ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤

---

## ğŸš€ ì„œë²„ ì‹¤í–‰ ë°©ë²•

### 1. ê¸°ë³¸ ì‹¤í–‰
```bash
cd /mnt/user-data/outputs
python main.py
```

### 2. ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
```bash
cd /mnt/user-data/outputs
nohup python main.py > server.log 2>&1 &
echo $! > server.pid
```

### 3. ì„œë²„ ì¢…ë£Œ
```bash
# PID íŒŒì¼ ì‚¬ìš©
kill $(cat server.pid)
rm server.pid

# ë˜ëŠ” ì§ì ‘ ì¢…ë£Œ
ps aux | grep "python main.py"
kill <PID>
```

---

## ğŸ§ª ìˆ˜ë™ í…ŒìŠ¤íŠ¸

### í…ŒìŠ¤íŠ¸ 1: í—¬ìŠ¤ì²´í¬

```bash
curl http://localhost:8002/health
```

**ì˜ˆìƒ ì‘ë‹µ:**
```json
{
  "status": "healthy",
  "service": "llm_server_modular",
  "model": "gpt-3.5-turbo",
  "documents": 0
}
```

---

### í…ŒìŠ¤íŠ¸ 2: ê°„ë‹¨í•œ ì±„íŒ… (ë©”ëª¨ë¦¬/RAG ì—†ìŒ)

```bash
curl -X POST http://localhost:8002/generate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "ì•ˆë…•í•˜ì„¸ìš”",
    "user_id": "test_user",
    "use_rag": false,
    "use_memory": false
  }'
```

**ì˜ˆìƒ ì‘ë‹µ:**
```json
{
  "success": true,
  "response": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
  "user_id": "test_user",
  "rag_used": false
}
```

---

### í…ŒìŠ¤íŠ¸ 3: ë¬¸ì„œ ì¶”ê°€

```bash
curl -X POST http://localhost:8002/documents/add \
  -H "Content-Type: application/json" \
  -d '{
    "content": "ë³µì§€ì„¼í„° ìš´ì˜ì‹œê°„: ì›”~ê¸ˆ 09:00-18:00",
    "metadata": {"source": "manual", "type": "info"}
  }'
```

**ì˜ˆìƒ ì‘ë‹µ:**
```json
{
  "success": true,
  "message": "ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ",
  "chunks_added": 1
}
```

---

### í…ŒìŠ¤íŠ¸ 4: ë¬¸ì„œ ê²€ìƒ‰

```bash
curl "http://localhost:8002/documents/search?query=ìš´ì˜ì‹œê°„&k=3"
```

**ì˜ˆìƒ ì‘ë‹µ:**
```json
{
  "success": true,
  "query": "ìš´ì˜ì‹œê°„",
  "documents": [
    "ë³µì§€ì„¼í„° ìš´ì˜ì‹œê°„: ì›”~ê¸ˆ 09:00-18:00"
  ]
}
```

---

### í…ŒìŠ¤íŠ¸ 5: RAG ê¸°ë°˜ ì±„íŒ…

```bash
curl -X POST http://localhost:8002/generate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "ë³µì§€ì„¼í„° ì–¸ì œ ì—´ì–´?",
    "user_id": "test_user",
    "use_rag": true,
    "use_memory": false
  }'
```

**ì˜ˆìƒ ì‘ë‹µ:**
```json
{
  "success": true,
  "response": "ë³µì§€ì„¼í„°ëŠ” ì›”ìš”ì¼ë¶€í„° ê¸ˆìš”ì¼ê¹Œì§€ ì˜¤ì „ 9ì‹œì— ë¬¸ì„ ì—½ë‹ˆë‹¤.",
  "user_id": "test_user",
  "rag_used": true,
  "source_documents": ["ë³µì§€ì„¼í„° ìš´ì˜ì‹œê°„: ì›”~ê¸ˆ 09:00-18:00"]
}
```

---

### í…ŒìŠ¤íŠ¸ 6: ëŒ€í™” ë©”ëª¨ë¦¬

**ì²« ë²ˆì§¸ ëŒ€í™”:**
```bash
curl -X POST http://localhost:8002/generate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼",
    "user_id": "memory_test",
    "use_rag": false,
    "use_memory": true
  }'
```

**ë‘ ë²ˆì§¸ ëŒ€í™”:**
```bash
curl -X POST http://localhost:8002/generate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "ë‚´ ì´ë¦„ì´ ë­ì•¼?",
    "user_id": "memory_test",
    "use_rag": false,
    "use_memory": true
  }'
```

**ì˜ˆìƒ ì‘ë‹µ:** "ì² ìˆ˜ë‹˜ì´ì‹œì£ !" (ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µ)

---

### í…ŒìŠ¤íŠ¸ 7: ë©”ëª¨ë¦¬ ì¡°íšŒ

```bash
curl http://localhost:8002/memory/memory_test
```

**ì˜ˆìƒ ì‘ë‹µ:**
```json
{
  "user_id": "memory_test",
  "conversation_count": 2,
  "history": [
    {
      "type": "human",
      "content": "ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼",
      "timestamp": "2024-11-12T..."
    },
    {
      "type": "ai",
      "content": "ì² ìˆ˜ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!",
      "timestamp": "2024-11-12T..."
    }
  ]
}
```

---

### í…ŒìŠ¤íŠ¸ 8: ì„œë²„ í†µê³„

```bash
curl http://localhost:8002/stats
```

**ì˜ˆìƒ ì‘ë‹µ:**
```json
{
  "active_users": 2,
  "total_conversations": 5,
  "documents_in_db": 1,
  "model": "gpt-3.5-turbo",
  "embedding_model": "text-embedding-3-small",
  "service": "llm_server_modular"
}
```

---

### í…ŒìŠ¤íŠ¸ 9: ì„¤ì • ì¡°íšŒ

```bash
curl http://localhost:8002/config
```

**ì˜ˆìƒ ì‘ë‹µ:**
```json
{
  "server": {
    "port": 8002,
    "host": "0.0.0.0"
  },
  "model": {
    "llm_model": "gpt-3.5-turbo",
    "embedding_model": "text-embedding-3-small"
  },
  "llm_parameters": {
    "temperature": 0.7,
    "max_tokens": 300
  }
}
```

---

## ğŸ Python í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸

### client_test.py ì‚¬ìš©

```bash
# ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ ìƒíƒœì—ì„œ
python client_test.py
```

### ì»¤ìŠ¤í…€ í…ŒìŠ¤íŠ¸ ì‘ì„±

```python
import requests

# 1. í—¬ìŠ¤ì²´í¬
response = requests.get("http://localhost:8002/health")
print(response.json())

# 2. ì±„íŒ…
response = requests.post(
    "http://localhost:8002/generate",
    json={
        "text": "ì•ˆë…•í•˜ì„¸ìš”",
        "user_id": "my_user"
    }
)
print(response.json())

# 3. ë¬¸ì„œ ì¶”ê°€
response = requests.post(
    "http://localhost:8002/documents/add",
    json={
        "content": "í…ŒìŠ¤íŠ¸ ë¬¸ì„œì…ë‹ˆë‹¤.",
        "metadata": {"source": "test"}
    }
)
print(response.json())
```

---

## ğŸ“Š ì¢…í•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
# ì„œë²„ ì‹œì‘
python main.py &
sleep 10

# ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_server.py

# ì„œë²„ ì¢…ë£Œ
pkill -f "python main.py"
```

---

## ğŸŒ API ë¬¸ì„œ í™•ì¸

ì„œë²„ ì‹¤í–‰ í›„ ë¸Œë¼ìš°ì €ì—ì„œ:

```
http://localhost:8002/docs
```

- Swagger UIë¡œ ëª¨ë“  API í™•ì¸ ê°€ëŠ¥
- ì§ì ‘ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- ìš”ì²­/ì‘ë‹µ ì˜ˆì‹œ í™•ì¸

---

## ğŸ” ë¡œê·¸ í™•ì¸

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ ë³´ê¸°
tail -f server.log

# ì—ëŸ¬ë§Œ ë³´ê¸°
grep -i error server.log

# ìµœê·¼ 100ì¤„ ë³´ê¸°
tail -100 server.log
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ì„œë²„ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸:

- [ ] `python main.py` ì‹¤í–‰ ì‹œ ì—ëŸ¬ ì—†ì´ ì‹œì‘
- [ ] `curl http://localhost:8002/health` ì‘ë‹µ ì •ìƒ
- [ ] API ë¬¸ì„œ (`/docs`) ì ‘ì† ê°€ëŠ¥
- [ ] ê°„ë‹¨í•œ ì±„íŒ… ìš”ì²­ ì„±ê³µ
- [ ] ë¬¸ì„œ ì¶”ê°€/ê²€ìƒ‰ ì„±ê³µ
- [ ] ëŒ€í™” ë©”ëª¨ë¦¬ ì‘ë™

---

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ì„œë²„ê°€ ì‹œì‘ë˜ì§€ ì•ŠëŠ” ê²½ìš°

1. **í¬íŠ¸ ì¶©ëŒ í™•ì¸**
   ```bash
   lsof -i :8002
   # ì‚¬ìš© ì¤‘ì´ë©´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
   kill <PID>
   ```

2. **íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸**
   ```bash
   pip install -r requirements.txt --break-system-packages
   ```

3. **API í‚¤ í™•ì¸**
   ```bash
   cat .env
   # OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
   ```

### API í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°

1. **ì„œë²„ ìƒíƒœ í™•ì¸**
   ```bash
   curl http://localhost:8002/health
   ```

2. **ë¡œê·¸ í™•ì¸**
   ```bash
   tail -50 server.log
   ```

3. **ë„¤íŠ¸ì›Œí¬ í™•ì¸**
   ```bash
   ping localhost
   ```

---

## ğŸ“ ì£¼ì˜ì‚¬í•­

1. **API í‚¤**: OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
2. **ë„¤íŠ¸ì›Œí¬**: ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤ (OpenAI API í˜¸ì¶œ)
3. **í¬íŠ¸**: 8002 í¬íŠ¸ê°€ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤
4. **ë””ë ‰í† ë¦¬**: `./chroma_db/`, `./chat_history/` ìë™ ìƒì„±ë©ë‹ˆë‹¤

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. âœ… ì„œë²„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
2. ë¼ìš°í„° ì„œë²„ì™€ ì—°ë™ í…ŒìŠ¤íŠ¸
3. TTS/STT ì„œë²„ì™€ í†µí•© í…ŒìŠ¤íŠ¸
4. ì‹¤ì œ ì–´ë¥´ì‹  ëŒ€ìƒ í…ŒìŠ¤íŠ¸
5. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

---

## ğŸ’¡ ìœ ìš©í•œ ëª…ë ¹ì–´

```bash
# ì„œë²„ í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep "python main.py"

# ì„œë²„ ë¡œê·¸ ì‹¤ì‹œê°„ ë³´ê¸°
tail -f server.log

# ë¬¸ì„œ ê°œìˆ˜ í™•ì¸
curl http://localhost:8002/documents/count

# ëª¨ë“  ë©”ëª¨ë¦¬ ì‚­ì œ
curl -X DELETE http://localhost:8002/memory/<user_id>

# ëª¨ë“  ë¬¸ì„œ ì‚­ì œ
curl -X DELETE http://localhost:8002/documents/clear
```
